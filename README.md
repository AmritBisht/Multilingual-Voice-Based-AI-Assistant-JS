# ğŸŒ Multilingual Voice-Based AI Assistant

A **voice-enabled AI chatbot** that supports **multiple languages**. Speak into your mic, and get intelligent responses from Google Gemini â€” with voice feedback!

Built using:
- ğŸ¤ Web Audio API + JS (frontend, Vercel)
- âš™ï¸ FastAPI backend (Render)
- ğŸ§  Google Gemini AI
- ğŸ—£ï¸ Google Speech Recognition API

---

## ğŸš€ Live Demo

ğŸ”— Try the live demo here : [ Click ](https://multilingual-voice-based-ai-git-4983bc-amrits-projects-1a6211f2.vercel.app)

ğŸ”— Frontend (Vercel): [https://your-vercel-app-url](https://multilingual-voice-based-ai-git-4983bc-amrits-projects-1a6211f2.vercel.app)

ğŸŒ Backend (Render): [https://your-render-app-url](https://dashboard.render.com/web/srv-cvo2vs49c44c73bhteo0/deploys/dep-cvoaid6mcj7s7380h9cg)

---

## ğŸ“¸ Features

âœ… Voice recording (manual + auto-stop after 20s)  
âœ… Translates speech to text in multiple languages  
âœ… AI-powered responses via **Google Gemini**  
âœ… Text-to-speech voice feedback  
âœ… User-friendly, responsive UI  
âœ… Status feedback (Listening / Processing...)

---

## ğŸ§  Tech Stack

| Layer         | Tech                                      |
|---------------|-------------------------------------------|
| Frontend      | HTML, CSS, JavaScript (Vercel)            |
| Backend       | FastAPI (Render)                          |
| Speech-to-Text| Google Speech Recognition                 |
| AI Model      | Google Gemini (via Generative AI SDK)     |
| Voice Output  | Web Speech API (SpeechSynthesis)          |

---

## ğŸ“ Project Structure

```
multilingual-voice-ai-assistant/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ main.py               # FastAPI backend
â”‚   â””â”€â”€ .env                  # Contains GOOGLE_API_KEY
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ index.html            # Web app with JS logic
â””â”€â”€ README.md
```

---

## ğŸ”‘ Environment Variables (Backend)

On **Render Dashboard**, add this in the "Environment" section:

```bash
GOOGLE_API_KEY=your_google_gemini_api_key_here
```

> âš ï¸ Ensure your `.env` is **not committed to Git**. FastAPI will use this to authenticate with Google Generative AI.

---

## ğŸ§ª How It Works

1. User clicks **Start** â†’ App records voice  
2. Audio is sent to backend â†’ Transcribed using Google STT  
3. Transcribed text is sent to Gemini â†’ AI generates response  
4. Response is returned â†’ Spoken out loud using Text-to-Speech  

---

## ğŸŒ Supported Languages

- English ğŸ‡ºğŸ‡¸ (`en-US`)
- Hindi ğŸ‡®ğŸ‡³ (`hi-IN`)
- French ğŸ‡«ğŸ‡· (`fr-FR`)
- Spanish ğŸ‡ªğŸ‡¸ (`es-ES`)

> You can add more languages by editing the `<select>` dropdown in `index.html`.

---

## âœ¨ User Feedback UX

- ğŸ™ï¸ **Listening...** appears during recording  
- ğŸ§  **Processing...** while waiting for AI response  
- ğŸ’¬ Shows user + AI messages in styled chat bubbles  
- ğŸ”Š AI speaks reply using your selected language

---

## ğŸ› ï¸ To Run Locally

### 1. Clone Repo

```bash
git clone https://github.com/your-username/multilingual-voice-ai-assistant.git
cd multilingual-voice-ai-assistant
```

### âš™ï¸ 2. Backend (FastAPI)

```bash
cd backend
pip install -r requirements.txt

# Create .env file
echo "GOOGLE_API_KEY=your_api_key_here" > .env

# Start backend
uvicorn main:app --reload
```

### ğŸŒ 3. Frontend (HTML + JS)

You can run this locally by just opening the file:

```bash
cd ../frontend
open index.html
```

Or, to deploy:

### ğŸ§¾ 3. Frontend Deployment (Vercel)

Go to [https://vercel.com](https://vercel.com)

1. Create a new project.
2. Upload your `index.html`.
3. Inside `index.html`, replace the backend URL in the `fetch()` call:

```javascript
const response = await fetch("https://your-backend-url.onrender.com/process_audio/", { ... });
```

4. Deploy and done ğŸ‰

---

## ğŸŒ Supported Languages

- English ğŸ‡ºğŸ‡¸ (`en-US`)
- Hindi ğŸ‡®ğŸ‡³ (`hi-IN`)
- French ğŸ‡«ğŸ‡· (`fr-FR`)
- Spanish ğŸ‡ªğŸ‡¸ (`es-ES`)

> You can add more in the `<select>` dropdown inside `index.html`.

---

## ğŸ’¬ UX Feedback

| Event                | UI Feedback           |
|----------------------|-----------------------|
| Recording Start      | "ğŸ™ï¸ Listening..."    |
| Recording End        | "ğŸ¤– Processing..."    |
| AI Reply             | Voice + Text Bubble   |

---

## ğŸ§  How It Works

1. User clicks record (manual start).
2. Audio is recorded for up to 20 seconds or until the user stops.
3. Sent to FastAPI â†’ converted from `.webm` to `.wav`.
4. Transcribed using Google Speech Recognition.
5. Sent to Google Gemini â†’ response generated.
6. AI response returned + spoken aloud via TTS.

---

## ğŸ’¡ Future Plans

- Persistent chat history (memory)
- Translate Gemini response back into the user's language
- More language support
- UI animation + avatars
- Mobile PWA support

---

## ğŸ™Œ Credits

- FastAPI
- Google Generative AI
- Pydub
- Web Speech API
- Render
- Vercel

